---
title: "Inflation Insight: Forecasting Australian Inflation Rate Using Bayesian VAR model"
author: "Gezhi Chen"

execute:
  echo: false
  
bibliography: references.bib
---

> **Abstract.** The purpose of this research is to explore the trend in Australia's inflation rate over the next two years using the Bayesian Vector Auto-regression (BVAR) model.

> **Keywords.** bsvars, quarto, R, Australia inflation rate

# Introduction

## Question Objective and Motivation

**Question:**

Will Australia's inflation rate fall back to the 2-3% inflation target range in 2025?

**Objective and Motivation:**

Inflation has always been a topic of interest for economists, as trends in the inflation rate provide essential guidance for key decisions by economic participants, thus playing a crucial role in the economic and social development of a country [@bernoth2021]. The Reserve Bank of Australia (RBA) forecasts that by 2025, inflation will fall back to the target range of 2% to 3% and reach the midpoint of this range by 2026. Influenced by the COVID-19 pandemic, Blot et al. deduced that the inflation rate is affected by a variety of factors, such as GDP, exchange rates, interest rates, and unemployment rates [@EuropeanParliament.2022]. Therefore, this study will assess the reasonableness of the RBA's inflation rate forecast for the next two years. During the COVID-19 period, Australia's inflation rate sharply rose to 7.8%, in response to which the RBA implemented a monetary tightening policy and began raising interest rates at the end of 2022, slowing the pace of rate hikes in the latter half of 2023. Hence, this report will further discuss whether the RBA has correctly assumed that its monetary policy measures have effectively curbed inflation.

```{r Start}
rm(list=ls())
```

```{r Library}
#| echo: false
#| message: false
#| warning: false

library(readabs)
library(readrba)
library(xts)
library(dplyr)
library(lubridate)    # quarterly data
library(corrplot)     # cor plot
library(fUnitRoots)   # ADF test - adfTest
library(tidyverse)    # for table
library(kableExtra)   # for print table
library(zoo)
library(ggplot2)      # plot in same graph
library(GIGrvg)       # GIG distribution
library(mvtnorm)      # Bvars forecast
library(plot3D)
library(HDInterval)   # hdi plot

```

```{r Colour}
#| echo: false
#| message: false
#| warning: false

blue1 = "blue"            # #0000FF
blue2 = "lightblue"       # #ADD8E6
blue3 = "royalblue"       # #4169E1
blue4 = "deepskyblue"     # #00BFFF
blue5 = "dodgerblue"      # #1E90FF
blue6 = "steelblue"       # #4682B4


green1  = "#05386B"
green2  = "#379683"
green3  = "#5CDB95"
green4  = "#8EE4AF"
green5  = "#EDF5E1"
green6  = "darkgreen"
```

## Data and Data Properties

### Data Selection and Rationale

-   **Direct Inflationary Indicators:**

    1.$cpi_t$: Consumer Price Index (CPI) from ABS.

    CPI directly measure inflation by follow formula:

    $$Inflation  = (\frac{CPI_{Quarter \ of \ These \ Year}}{CPI_{Quarter \ of \ Previous \ Year} } - 1 )\times 100$$ {#eq-1}

    CPI is the basic data for measuring inflation. It is more stable and less affected by seasonal factors and short-term fluctuations than the annual inflation rate from which it is derived. In VAR, raw time series data rather than rates of change are used to capture and model the dynamic nature of the data.

    2.$infexp_t$: Business inflation expectations -- 3-months ahead from RBA

    Inflation expectations often guide consumer and business behavior; if inflation is expected to rise, they might make purchases and raise prices in advance, thus driving actual inflation up in the short term. Meanwhile, central banks closely monitor inflation expectations, adjusting monetary policies to influence these expectations and control actual inflation to maintain price stability.

-   **Economic Activity and Policy Indicators:**

    3.  $gdp_t$: Gross Domestic Product (GDP) from ABS.

    GDP reflects the size and growth rate of a country's economy. When GDP increases, it indicates increased economic activity, which can lead to demand-pull inflation because increased demand may exceed current production capacity, pushing up prices.

    4.  $crt_t$: Cash rate target published by RBA.

    This is the main tool used by the RBA to influence economic activity. Raising the cash rate is usually aimed at reducing borrowing and spending, thereby reducing inflationary pressures.

    5.  $unemp_t$: Unemployment rate from ABS.

    It indicate the level of slack in the labor market, influencing wage-push inflation.

    6.  $m_t$: Money aggregate (Broad money) from RBA.

    'Broad money' is defined as 'M3' plus 'Other borrowings from private sector by AFIs'. When the growth rate of broad money supply in an economy exceeds the growth rate of its real output, it leads to more money chasing the same amount of goods and services, causing price levels to rise, i.e., inflation. Therefore, central banks like the Reserve Bank of Australia (RBA) adjust interest rates and other tools to control the growth of broad money to achieve their inflation targets.

-   **Market and External Trade Indicators:**

    7.  $export_t$: International exports from ABS.

    It affects trade balance and currency strength, influencing imported inflation.

    8.  $import_t$: International imports from ABS.

    Directly affect inflation through the cost of imported goods.

    9.  $aord_t$: All Ordinaries Index (AORD) from yahoo finance.

    It reflects investor confidence and economic activity which can be pre-emptive indicators of inflation.

    10. $exr_t$: AUD/USD exchange rate from RBA.

    It affects the price of imports and exports, contributing to inflation.

```{r Data Downloading, fig.pos="H"}
#| echo: false
#| message: false
#| warning: false


### Data downloading

# 1.Inflation / CPI 
# 6401.0 Consumer Price Index, Australia
# series_id = "A2325846C": Index Numbers ;  All groups CPI ;  Australia ;
cpi_download      = read_abs(series_id = "A2325846C")     
cpi_data          = xts(cpi_download$value, cpi_download$date)
correct_dates     = seq(as.Date("1948-10-01"), by="quarter", length.out=length(cpi_data))
correct_dates     = floor_date(correct_dates, "month") - days(1)
index(cpi_data)   = correct_dates


# 2.GDP
# 5206.0 Australian National Accounts: National Income, Expenditure and Product
# series_id = "A2304404C": GDP per capita: Chain volume measures ;
gdp_download      = read_abs(series_id = "A2304404C")     
gdp_data          = xts(gdp_download$value, gdp_download$date)
correct_dates     = seq(as.Date("1959-10-01"), by="quarter", length.out=length(gdp_data))
correct_dates     = floor_date(correct_dates, "month") - days(1)
index(gdp_data)   = correct_dates


# 3.Cash rate target

crt_download      = read_rba(series_id = "FIRMMCRTD")   
crt_data          = xts(crt_download$value, crt_download$date)
quarter_ends      = endpoints(crt_data , on = "quarters")
crt_data          = crt_data[quarter_ends]
correct_dates     = seq(as.Date("1990-04-01"), by="quarter", length.out=length(crt_data))
correct_dates     = floor_date(correct_dates, "month") - days(1)
index(crt_data)   = correct_dates


# 4.Unemployment rate
# 6202.0 Labour Force, Australia
# series_id = "A84423050A": Unemployment rate ;  Persons ; seasonal adjust
unemp_download      = read_abs(series_id = "A84423050A")     
unemp_data          = xts(unemp_download$value, unemp_download$date)
quarter_ends        = endpoints(unemp_data , on = "quarters")
unemp_data          = unemp_data[quarter_ends]
correct_dates       = seq(as.Date("1978-04-01"), by="quarter", length.out=length(unemp_data))
correct_dates       = floor_date(correct_dates, "month") - days(1)
index(unemp_data)   = correct_dates


# 5.Export
# 5368.0 International Trade in Goods
# series_id = "A2718603V": Debits, Total goods ;
export_download     = read_abs(series_id = "A2718603V")     
export_data         = xts(export_download$value, export_download$date)
export_data         = abs(export_data)
quarter_ends        = endpoints(export_data , on = "quarters")
export_data         = export_data[quarter_ends]
correct_dates       = seq(as.Date("1971-10-01"), by="quarter", length.out=length(export_data))
correct_dates       = floor_date(correct_dates, "month") - days(1)
index(export_data)  = correct_dates


# 6.Import
# 5368.0 International Trade in Goods
# series_id = "A2718577A": Credits, Total goods ;
import_download     = read_abs(series_id = "A2718577A")     
import_data         = xts(import_download$value, import_download$date)
quarter_ends        = endpoints(import_data , on = "quarters")
import_data         = import_data[quarter_ends]
correct_dates       = seq(as.Date("1971-10-01"), by="quarter", length.out=length(import_data))
correct_dates       = floor_date(correct_dates, "month") - days(1)
index(import_data)  = correct_dates

# 7. Broad money
# D3 MONETARY AGGREGATES
# Series ID: DMABMN: Broad money – For series breaks see Series Breaks 'Broad money' is defined as 'M3' plus ‘Other borrowings from private sector by AFIs.

m_download        = read_rba(series_id = "DMABMN")   
m_data            = xts(m_download$value, m_download$date)
quarter_ends      = endpoints(m_data , on = "quarters")
m_data            = m_data[quarter_ends]
correct_dates     = seq(as.Date("1976-10-01"), by="quarter", length.out=length(m_data))
correct_dates     = floor_date(correct_dates, "month") - days(1)
index(m_data)     = correct_dates


# 8. Business inflation expectations – 3-months ahead
# G3 INFLATION EXPECTATIONS 
# Series ID: GBUSEXP: Survey measure of business expectations; Increase in final prices for 3-months ahead; Annualised

infexp_download      = read_rba(series_id = "GBUSEXP")   
infexp_data          = xts(infexp_download$value, infexp_download$date)
quarter_ends         = endpoints(infexp_data , on = "quarters")
infexp_data          = infexp_data[quarter_ends]
correct_dates        = seq(as.Date("1989-10-01"), by="quarter", length.out=length(infexp_data))
correct_dates        = floor_date(correct_dates, "month") - days(1)
index(infexp_data)   = correct_dates

# 9.AORD
aord_link           = "https://query1.finance.yahoo.com/v7/finance/download/%5EAORD?period1=460339200&period2=1712793600&interval=1mo&filter=history&frequency=1mo&includeAdjustedClose=true"
aord_download       = read.csv(aord_link)
aord_data           = data.frame(aord_download[,1], aord_download[,6])
colnames(aord_data) = c('date', 'aord')
aord_data$date      = as.Date(as.character(aord_data$date),format="%Y-%m-%d") 
# aord_data$aord      = as.numeric(na_if(aord_data$aord, "null"))
aord_data           = na.omit(aord_data)
aord_data           = xts(aord_data$aord, aord_data$date)
aord_data           = to.quarterly(aord_data, OHLC = FALSE)
correct_dates       = seq(as.Date("1985-04-01"), by="quarter", length.out=length(aord_data))
correct_dates       = floor_date(correct_dates, "month") - days(1)
index(aord_data)    = correct_dates

# 10. AUD/USD

exr_download      = read_rba(series_id = "FXRUSD", frequency("Monthly"))   
exr_data          = xts(exr_download$value, exr_download$date)
quarter_ends      = endpoints(exr_data, on = "quarters")
exr_data          = exr_data[quarter_ends]
correct_dates     = seq(as.Date("1969-10-01"), by="quarter", length.out=length(exr_data))
correct_dates     = floor_date(correct_dates, "month") - days(1)
index(exr_data)   = correct_dates


```

```{r Data Combine, fig.pos="H"}
#| echo: false
#| message: false
#| warning: false

# All Variables
all_data             = na.omit(merge(cpi_data,    infexp_data, 
                                     gdp_data,    crt_data, 
                                     unemp_data,  m_data,  
                                     export_data, import_data, 
                                     aord_data,   exr_data ))

colnames(all_data)   = c("cpi_data",    "infexp_data", 
                         "gdp_data",    "crt_data", 
                         "unemp_data",  "m_data", 
                         "export_data", "import_data",
                         "aord_data",   "exr_data")
```

Following Figure shows the correlation between CPI and other variables.

Despite the low direct correlation between inflation expectations and CPI, inflation expectations may more closely reflect concerns about core inflation, which excludes volatile items like food and energy, whereas the CPI includes all items. If the trends between core inflation and overall inflation differ, this discrepancy can reduce the correlation between inflation expectations and the CPI. However, inflation expectations provide additional insight into how future economic conditions are perceived by consumers, businesses, and investors. This forward-looking perspective is important as it might influence economic decisions that are not immediately apparent through current CPI data.

Exchange rate fluctuations are typically sensitive to immediate market sentiment and short-term capital flows, whereas the CPI, as a measure of past price level changes, often exhibits a lag in responding to market changes. Even if the correlation between the CPI and the AUD/USD exchange rate is low, including this variable can help researchers understand economic changes from a broader perspective. For example, changes in the exchange rate can indirectly affect domestic price levels through the cost of imports, especially in open economies.

It should be noted that the unemployment rate exhibits a weak correlation with the CPI. This could be attributed to the Phillips Curve, which illustrates a short-term inverse relationship between unemployment and inflation. Over the long term, however, this correlation may diminish due to various influencing factors. For instance, following COVID, the inflation rate in the United States has been continuously rising due to the bankruptcy crisis among small and medium-sized enterprises (SMEs), part of which is attributed to the inadequate supply of export goods produced by SMEs leading to a decline in export volumes, thereby driving up the domestic inflation rate in the US [@kalemli-ozcan2020]. This impact can be seen as an indirect effect of rising unemployment rates on inflation. Therefore, despite the weak correlation between unemployment rate and CPI, it is still important to include it in the model for a comprehensive analysis.

```{r Corr Plot, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

## plot corr table
cor_matrix          = round(cor(all_data), 4)

corrplot(cor_matrix, method = "color", 
         type = "upper", 
         tl.srt = 45,    
         tl.col = "black",
         tl.cex = 0.6,  
         col = colorRampPalette(c("darkblue", "#FFFFFF", "darkred"))(200), 
         addCoef.col = "darkgrey", 
         number.cex = 0.5,     
         diag = FALSE, 
         title = "Correlation Matrix", 
         mar = c(0, 0, 2, 0),
         cl.lim = c(-1, 1), 
         cl.cex = 0.3, 
         cl.ratio = 0.1
)
```

Figure 1 Correlation Matrix

In summary, the dataset included data from 1990Q2 to 2023Q4, total 136 observation points with 10 variables.

### Data Transformation

-   **Quarterly Transformation**

All data have been quarterly converted by selecting the data on the last day of the quarter as the observation. One of the reasons for not using monthly data is that high-quality quarterly economic data are more readily available compared to monthly data. In this report, the key data, CPI, which published on ABS, and the monthly data starting point is Q3 of 2017. Since the research wanted to capture longer-term data, quarterly data was considered. Also, policymakers and economists often rely more on quarterly data for decision-making because it provides a more stable and comprehensive view of economic conditions to some extent. This stability is key to understanding and predicting economic trends, especially when considering the long-term impacts of policies.

-   **Log Transformation**

Based on the line graph of the original data below (Figure 2), we can observe that exponentially growing variables need to be linearized, such as $cpi_t$, $gdp_t$, $m_t$, $export_t$, $import_t$, $aord_t$. Therefore, its logarithmically transformed form will be used in the following analysis.

```{r Data plot, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

### Data plot

## Line plot for original data
par(mfcol = c(5, 2), mar = c(2, 2, 2, 2))

for (i in 1:10) {
  ts.plot(all_data[, i], main = colnames(all_data)[i], 
          ylab = "", xlab = "", col = blue1)
}
```

Figure 2 Line plot of original data

```{r Log transfomation}

## log transformation for exp data

lcpi_data     = log(cpi_data)
lgdp_data     = log(gdp_data)
lm_data       = log(m_data)
lexport_data  = log(export_data)
limport_data  = log(import_data)
laord_data    = log(aord_data)

# All Variables after log
all_data             = na.omit(merge(lcpi_data,     infexp_data, 
                                     lgdp_data,     crt_data, 
                                     unemp_data,    lm_data,  
                                     lexport_data,  limport_data, 
                                     laord_data,    exr_data ))

colnames(all_data)   = c("lcpi_data",      "infexp_data", 
                         "lgdp_data",      "crt_data", 
                         "unemp_data",     "lm_data", 
                         "lexport_data",   "limport_data",
                         "laord_data",     "exr_data")
```

-   **Integration transformation**

According to ACF plot for all data (Figure 3), we can see all data with autocorrelation. It suggests that the series is not white noise and might not be stationary.

```{r ACF plot, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

## ACF plot
par(mfcol = c(5, 2), mar=c(2,2,2,2))
for (i in 1:10){
  acf = acf(all_data[,i], plot = FALSE)[1:20]
  plot(acf, main = "")
  title(main = paste(colnames(all_data)[i]), line = 0.5)
}
```

Figure 3 ACF Plot for all data

Considering the selection of the order of single-order integration, the unit root test (ADF test) is used and the p value is used to determine its significance. A small p-value means the null hypothesis is rejected (non-stationary).

According to Table 1, we can see that $infexp_t$, $lm_t$, require more than first order integration, while other require first-order integration(under 5% level of confidence).

```{r ACF test, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

## AR

# find the optimal lag 
ar_results <- list()

for (i in 1:ncol(all_data)) {
  ol.aic.ar <- ar(all_data[,i], order.max=20, aic=TRUE, method="ols")
  
  ar_results[[colnames(all_data)[i]]] <- ol.aic.ar$order
}

## ADF test

# ol.cpi.aic.ar$order
adf.cpi   = adfTest(all_data[,1], lags=5, type="c")              # don't reject -> non-stationary
dadf.cpi  = adfTest(diff(all_data[,1]), lags=4, type="nc")        # don't reject -> non-stationary

# ol.infexp.aic.ar$order
adf.infexp   = adfTest(all_data[,2], lags=5, type="c")               # don't reject -> non-stationary
dadf.infexp  = adfTest(diff(all_data[,2]), lags=4, type="nc")        # reject -> (I1 is stationary)

# ol.gdp.aic.ar$order
adf.gdp   = adfTest(all_data[,3], lags=7, type="c")              # don't reject -> non-stationary
dadf.gdp  = adfTest(diff(all_data[,3]), lags=6, type="nc")       # reject -> (I1 is stationary)

# ol.crt.aic.ar$order
adf.crt  = adfTest(all_data[,4], lags=20, type="c")               # don't reject -> non-stationary
dadf.crt = adfTest(diff(all_data[,4]), lags=19, type="nc")        # reject -> (I1 is stationary)

# ol.unemp.aic.ar$order
adf.unemp  = adfTest(all_data[,5], lags=5, type="c")           # don't reject -> non-stationary
dadf.unemp = adfTest(diff(all_data[,5]), lags=4, type="nc")    # reject -> (I1 is stationary)


# ol.m.aic.ar$order
adf.m      = adfTest(all_data[,6], lags=5, type="c")           # don't reject -> non-stationary
dadf.m     = adfTest(diff(all_data[,6]), lags=4, type="nc")    # don't reject -> non-stationary

# ol.export.aic.ar$order
adf.export  = adfTest(all_data[,7], lags=6, type="c")           # don't reject -> non-stationary
dadf.export = adfTest(diff(all_data[,7]), lags=5, type="nc")    # reject -> (I1 is stationary)



# ol.import.aic.ar$order
adf.import  = adfTest(all_data[,8], lags=5, type="c")           # don't reject -> non-stationary
dadf.import = adfTest(diff(all_data[,8]), lags=4, type="nc")    # reject -> (I1 is stationary)

# ol.aord.aic.ar$order
adf.aord   = adfTest(all_data[,9], lags=1, type="c")               # don't reject -> non-stationary
dadf.aord  = adfTest(diff(all_data[,9]), lags=0, type="nc")        # reject -> (I1 is stationary)


# ol.exr.aic.ar$order
adf.exr   = adfTest(all_data[,10], lags=1, type="c")               # don't reject -> non-stationary
dadf.exr  = adfTest(diff(all_data[,10]), lags=0, type="nc")        # reject -> (I1 is stationary)

Unit_Root_Test_table <- 
  tibble( " " = c("lcpi", "infexp", "lgdp", "crt", "unemp", "lm", "lexport", "limport", "laord", "exr"),
          "p value of ADF test of AR" 
          = round(c(adf.cpi@test$p.value,     adf.infexp@test$p.value,
                    adf.gdp@test$p.value,     adf.crt@test$p.value,    
                    adf.unemp@test$p.value,   adf.m@test$p.value,
                    adf.export@test$p.value,  adf.import@test$p.value,
                    adf.aord@test$p.value,    adf.exr@test$p.value),4),
          "p value of ADF test of diff-AR" 
          = round(c(dadf.cpi@test$p.value,    dadf.infexp@test$p.value,
                    dadf.gdp@test$p.value,    dadf.crt@test$p.value,    
                    dadf.unemp@test$p.value,  dadf.m@test$p.value,
                    dadf.export@test$p.value, dadf.import@test$p.value,   
                    dadf.aord@test$p.value,   dadf.exr@test$p.value),4),
          
          "conclusion" 
          = c("lcpi~I(n)",     "infexp~I(1)", 
              "lgdp~I(1)",     "crt~I(1)",    
              "unemp~I(1)",    "lm~I(n)", 
              "lexport~I(1)",  "limport~I(1)", 
              "laord~I(1)",    "exr~I(1)"
          ),
  )

kable(Unit_Root_Test_table, align = "c") %>% 
  kable_styling(font_size = 8, 
                fixed_thead = TRUE, 
                full_width = FALSE, 
                position = "center",
                latex_options = c("HOLD_position"),
                bootstrap_options = c("striped", "hover", "bordered", "responsive", "dark"))

```

Table 1 Unit root test for all data

Consider that differencing might eliminate some of the long-term information (like trends) within the data, and considering the Minnesota prior method can be effective with nonstationary data, we have opted apply not differencing to any of the data sets.

```{r Diff Data, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

# all_data         = na.omit(diff(all_data))

```

After logarithmic transformation of part of the data, the line plot of the dataset is as shown below (Figure 4). The dataset still retains some trend characteristics. For example, almost all variables showed significant changes before and after COVID (the x-aisx is 120).

```{r Data Plot 2, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

## Line plot for after transformation data
par(mfcol = c(5, 2), mar = c(2, 2, 2, 2))

for (i in 1:10) {
  ts.plot(all_data[, i], main = colnames(all_data)[i], 
          ylab = "", xlab = "", col = green3)
}
```

Figure 4 Line plot of adjusted data

### Importance of Key Variables Analysis

```{r Compute inf, fig.align='center',fig.pos='H'}
cpi_lag4 = lag(cpi_data, 4)
inf_data = ((cpi_data / cpi_lag4)-1)*100
inf_data = na.omit(inf_data)

```

```{r Combine Key Data, fig.align='center',fig.pos='H'}
key_data           = na.omit(merge(inf_data, infexp_data, crt_data))
colnames(key_data) = c("inf_data", "infexp_data", "crt_data")
                        
```

The model selects ten variables related to Australian inflation. Among the variables most directly related to inflation is inflation and inflation target. Meanwhile, because we use CPI as key variable, we first need to calculate quarterly inflation through CPI. Below we focus on analyzing these two variables:

-   The actual and expected inflation rates appear to move in tandem over much of the time period, suggesting that expectations may be influenced by current and past inflation rates, or vice versa. At the same time, we see that people's expectations for inflation are relatively conservative. For example, during the COVID, the expected inflation was around 5%, but the actual inflation later surged to about 7.8%.

-   Regarding the specific inflation zone of 2-3%, it appears that both the expected and actual inflation rates oscillate into this range periodically. However, it seems that starting just before 2020, there's a pronounced peak where expected inflation sharply rises above the actual inflation rate, which then converges back into the 2-3% range shortly after (although actual inflation rate still need some time). So we can foresee that inflation will indeed fall back to the 2-3% range in the near future.

```{r Plot inf infexp, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

data_df = fortify.zoo(key_data)

par(mfcol = c(1, 1), mar = c(4, 4, 2, 2) +2)

plot(data_df$Index, data_df$inf_data, type = "l", col = blue1,
     xlab = "Date", ylab = "Rate (%)", ylim = c(0, 11))

rect(xleft = min(data_df$Index), xright = max(data_df$Index),
     ybottom = 2, ytop = 3, col = green5, border = NA)  

lines(data_df$Index, data_df$inf_data, col = blue3)
lines(data_df$Index, data_df$infexp_data, col = green2)

abline(h = 0, col = green1, lty = 1) 


legend("topright", legend = c("Inflation Rate", "Expected Inflation Rate"),
       col = c(blue3, green2), lty = 1, cex = 0.6)
title(main = "Inflation Rate vs Expected Inflation Rate")

```

Figure 5 Inflation Rate vs Expected Inflation Rate

## Model and Hypothesis

Regarding model selection, the VAR model, capable of concurrently integrating the effects of multiple economic indicators on inflation such as GDP, exchange rates, interest rates, unemployment rates, and other variables, offers coherent and reliable results by analyzing the time series of these variables for data analysis and forecasting [@stock2001].

Based on the above analysis, all 10 variables play an important role in the fitting of the model. Use VAR(p) model for modeling, where N=10, T=135.

$$
\begin{align}
y_t &= \mu_0 + A_1y_{t-1} +...+A_py_{t-p} +\epsilon_t 
\\
\epsilon_t|Y_{t-1} &\sim iid \mathcal{N}_{10}(\textbf{0}_{10}, \Sigma)
\end{align}
$$ {#eq-2}

In matrix notation:

$$
\begin{align}
Y &= X A +E 
\\
E|X &\sim \mathcal{MN}_{T\times 10}(\textbf{0},\Sigma,I_T)
\end{align} 
$$ {#eq-3}

-   $Y$ is $T\times 10$matrix of dependent variables.

-   $X$ is $T \times (1 + 10p)$ matrix of independent variables.

-   $A$ is the matrix of coefficients, which includes the constant term $\mu_0$ and the autoregressive coefficients.

$$
Y=
\begin{bmatrix}
y_{lcpi,1} & y_{infexp,1} & y_{lgdp,1} & y_{crt,1} & y_{unemp,1} & y_{lm,1} & y_{lexport,1} & y_{limport,1} & y_{laord,1} & y_{exr,1}\\
\ y_{lcpi,2} & y_{infexp,2} & y_{lgdp,2} & y_{crt,2} & y_{unemp,2} & y_{lm,2} & y_{lexport,2} & y_{limport,2} & y_{laord,2} & y_{exr,2} \\
\vdots  & \vdots  & \vdots& \vdots& \vdots& \vdots& \vdots& \vdots& \vdots & \vdots  \\
y_{lcpi,T} & y_{infexp,T} & y_{lgdp,T} & y_{crt,T} & y_{unemp,T} & y_{lm,T} & y_{lexport,T} & y_{limport,T} & y_{laord,T} & y_{exr,T}\\
\end{bmatrix}_{T \times 10}
$$

$$
X=\begin{bmatrix}
1 & y_{lcpi,t-1} & y_{infexp,t-1} & \ldots & y_{exr,t-1} & \ldots & y_{lcpi,t-p} & y_{infexp,t-p} & \ldots &  y_{exr,t-p} \\
1 & y_{lcpi,t-2} & y_{infexp,t-2} & \ldots & y_{exr,t-2} & \ldots & y_{lcpi,t-p-1} & y_{infexp,t-p-1} & \ldots &  y_{exr,t-p-1} \\
\vdots & \vdots & \vdots & \ddots & \vdots & \ddots & \vdots & \vdots &  \ddots & \vdots \\
1 & y_{lcpi,1} & y_{infexp,1} & \ldots & y_{exr,1} & \ldots & y_{lcpi,1-p} & y_{infexp,1-p} & \ldots &  y_{exr,1-p}\\
\end{bmatrix}_{T\times (1+10p)}
$$

$$
A = \begin{bmatrix}
\mu_{lcpi} & \mu_{infexp} & \ldots & \mu_{lexr} \\
A_{1,lcpi}^{(1)} & A_{1,infexp}^{(1)} & \ldots & A_{1,exr}^{(1)} \\
A_{2,lpci}^{(1)} & A_{2,infexp}^{(1)} & \ldots & A_{2,exr}^{(1)} \\
\vdots  & \vdots  & \ddots & \vdots  \\
A_{10,lcpi}^{(1)} & A_{10, infexp}^{(1)} & \ldots & A_{10,exr}^{(1)} \\
\vdots  & \vdots  & \ddots & \vdots  \\
A_{1,lcpi}^{(p)} & A_{1,infexp}^{(p)} & \ldots & A_{1,exr}^{(p)} \\
A_{2,lcpi}^{(p)} & A_{2,infexp}^{(p)} & \ldots & A_{2,exr}^{(p)} \\
\vdots  & \vdots  & \ddots & \vdots  \\
A_{10,lcpi}^{(p)} & A_{10,infexp}^{(p)} & \ldots & A_{10,exr}^{(p)} \\
\end{bmatrix}_{(1 + 10p)\times 10}
$$

$$
\begin{align*}
E &= 
\begin{bmatrix}
\epsilon_{1,lcpi} & \epsilon_{1,infexp} & \ldots & \epsilon_{1,exr} \\
\epsilon_{2,lcpi} & \epsilon_{2,infexp} & \ldots & \epsilon_{2,exr} \\
\vdots & \vdots & \ddots & \vdots \\
\epsilon_{T,lcpi} & \epsilon_{T,infexp} & \ldots & \epsilon_{T,exr}
\end{bmatrix}_{T\times 10}
\\
\end{align*}
$$

### Model Application and Objective Fulfillment

Based on the model above, we will employ VAR of order p to carry out forecasts for the next two years. Given that the data is quarterly, setting the forecast horizon (h) to 8 quarters for our iterative forecasting process.

In the forecasting process, we will concentrate on determining the conditional mean and confidence interval of the projected CPI, denoted as $lcpi_{T+h|T}$. Subsequently, we'll utilize the forecasted (log) CPI values to calculate the inflation rate and assess whether it aligns with the target inflation range of 2-3%.

## Estimation Procedure and Algorithm

### Basic Model

#### Prior Distribution and Posterier Distribution Specified

The basic model based on the natural-conjugate prior distribution, which is specified as a matrix normal inverse Wishart distribution[@wozniak2016]. Minnesota prior with some stylised facts about the macroeconomic time series, since $lcpi_t$ and $lm_t$ are unit root non-stationary and other all variables are stationary, is applied to form the specifications of the prior distribution.

The estimation procedures to draw from the posterior follows the steps below:

**Step 1**: Prior distribution is presented below. We will specify $\underline{A}$, $\underline{V}$, $\underline{S}$ and $\underline{v}$.

$$
\begin{align}
p(A,\Sigma) &\propto L(A,\Sigma | Y,X) \ p(A|\Sigma) \ p(\Sigma) 
\\
p(A,\Sigma|Y,X) &= p(A|Y,X,\Sigma) \ p(\Sigma|Y,X) 
\\
\\
A|\Sigma &\sim \mathcal{MN}_{K\times N}(\underline{A}, \Sigma,\underline{V}) 
\\ 
\Sigma &\sim \mathcal{IW}_{N}(\underline{S}, \underline{\nu})
\end{align}
$$

-   $\underline{A}$ is a $K \times 10$ matrix, reflect the random walk with no drift process on the first lag of diagonal, and 0 elsewhere.

$$
\underline{A} = \left[ \underbrace{\textbf{0}_{10\times 1}}_{intercept} \quad  
\underbrace{
\begin{matrix} 
1 & \cdots  &  0 & \cdots &  0 \\
\vdots  & \ddots  & \vdots  & \ddots&  \vdots \\
0 & \cdots  & 1 & \cdots&  0 \\
\vdots  & \ddots  & \vdots  & \ddots&  \vdots \\
0 & \cdots  &  0 & \cdots &  1\\
\end{matrix}_{10\times10} \quad 
\begin{matrix}
0 & \cdots  &  0\\
\vdots  & \ddots  & \vdots  \\
0 & \cdots  & 0
\end{matrix}
_{10\times10(p-1))}}_{N\times(K-1)} 
\right]' 
$$

-   $\underline{V}$ represents the shrinking level of the specified $\underline{A}$. It's a $K$ vector diagonal matrix with the diagonal elements set to be the desired shrinking level.

$$
\underline{V} = diag\left[ \underbrace{\kappa_{2}}_{intercept} \quad \underbrace{\kappa_{1}(\textbf{p} ^{-2}\otimes I^{'}_{N})}_{A_{1} \ to \ A_{p}}  \right]
$$

-   $\underline{S}$ is $10\times10$ symmetric matrix where the diagonal represents the variances of individual variables (diagonal of $\Sigma$) and the off-diagonals are 0.

-   $\underline{v}$ is $N+2$, and it is a single values because variance is assumed to be the same for all elements of $\Sigma$.

**Step 2**: Posterior distribution shows below with the implementation of the specification in Step 1

$$
\begin{align}
p(A,\Sigma | Y,X) &= p(A|Y,X,\Sigma) \ p(\Sigma|Y,X) 
\\
 p(A|Y,X,\Sigma) &\sim \mathcal{MN}_{K\times N}(\overline{A}, \Sigma,\overline{V} ) 
\\
 p(\Sigma|Y,X) &\sim \mathcal{IW}_{N}(\overline{S}, \overline{\nu})
 \end{align}
$$

Therefore we can get:

$$
\begin{align}
\overline{A} &= \overline{V}(X'Y+\underline{V}^{-1}\underline{A}) 
\\
\overline{V} &= (X'X + \underline{V}^{-1})^{-1} 
\\ 
\overline{S} &= \underline{S}+Y'Y+\underline{A'} \ \underline{V}^{-1}\underline{A}-\overline{A'}\overline{V}^{-1}\overline{A} 
\\ 
\overline{v} &= T + \underline{\nu}
\end{align}
$$

**Step 3**: As $\overline{A}$, $\overline{V}$, $\overline{S}$ and $\overline{v}$ are specified:

At each iteration $s$:

1.  Draw $\Sigma^{(s)}$ from $\mathcal{IW}_{10}(\overline{S}, \overline{v})$, and take $\Sigma^{(s)}$ as known

2.  Draw $A^{(s)}$ from $\mathcal{MN}_{K\times 10}(\overline{A}, \Sigma,\overline{V} )$ by insert $\Sigma^{(s)}$

Output is the sample draws from the joint posterior distribution $\left\{ {A^{(s)}, \Sigma^{(s)}} \right\}^{S}_{s=1}$.

```{r Stat Setup, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

set.seed(11)

```

Function below is `posterior.draws`:

```{r Basic Model, fig.align='center',fig.pos='H'}
#| echo: true
#| message: false
#| warning: false

## Posterior sample draw function for basic model(posterior.draws)
posterior.draws       = function (S, Y, X){
  
    # normal-inverse Wishard posterior parameters
    V.bar.inv         = t(X)%*%X + diag(1/diag(V.prior))
    V.bar             = solve(V.bar.inv)
    A.bar             = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)
    nu.bar            = nrow(Y) + nu.prior
    S.bar             = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
    S.bar.inv         = solve(S.bar)
    
    # posterior draws 
    Sigma.posterior   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)
    Sigma.posterior   = apply(Sigma.posterior,3,solve)
    Sigma.posterior   = array(Sigma.posterior,c(N,N,S))
    A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S))
    L                 = t(chol(V.bar))
    
    for (s in 1:S){
      A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%chol(Sigma.posterior[,,s])
    }

    output            = list(A.posterior=A.posterior, Sigma.posterior=Sigma.posterior)
    return(output)
}
```


#### Function Proofing

Consider Bi-variate Gaussian random walk process:

$$
y_t = 
\begin{bmatrix}
y_{t,1} \\
y_{t,2}
\end{bmatrix} = 
\begin{bmatrix}
y_{t-1,1} \\
y_{t-1,2}
\end{bmatrix} + 
\begin{bmatrix}
\epsilon_{t,1} \\
\epsilon_{t,2}
\end{bmatrix} 
, where   \  \ 
\epsilon_{t,1} \sim \mathcal{N}(0,1)  \ and \ 
\epsilon_{t,2} \sim \mathcal{N}(0,1)
$$

$$ 
Y = \begin{bmatrix}
y_2' \\
y_3' \\
\vdots \\
y_n'
\end{bmatrix},
\quad
X = \begin{bmatrix}
1 \quad y_1' \\
1 \quad y_2' \\
\vdots \quad \vdots \\
1 \quad y_{n-1}'
\end{bmatrix}
$$



```{r Basic Model Function Proof, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

e1 = cumsum(rnorm(1000, 0, sd=1))
e2 = cumsum(rnorm(1000, 0, sd=1))
e  = cbind(e1,e2)

## Define data X, Y 
Y = ts(e[2:nrow(e),], frequency=1)
X = matrix(1,nrow(Y),1)
X = cbind(X,e[2:nrow(e)-1,])


## Test on basic model
N           = ncol(Y)                          # N=2
p           = frequency(Y)
A.hat       = solve(t(X)%*%X)%*%t(X)%*%Y
Sigma.hat   = t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)

# Prior distribution (with Minnesota prior)
kappa.1             = 1                                    # shrinkage for A1 to Ap
kappa.2             = 100                                  # shrinkage for constant 
A.prior             = matrix(0,nrow(A.hat),ncol(A.hat))
A.prior[2:(N + 1),] = diag(N)
V.prior             = diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N)))
S.prior             = diag(diag(Sigma.hat))
nu.prior            = N+2

# Applying function 
posterior.sample.draws.p = posterior.draws(S=10000, Y=Y, X=X)

```


After estimating a model that includes a constant term and one lag using artificial data, we observe that the posterior mean of the autoregressive and covariance matrices closely approximates an identity matrix, and the posterior mean of the constant term is nearly a vector of zeros.

 - The posterior mean of the $A$ is:
 

```{r Basic Model Proof A, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

basic.model.proof.A <- 
  tibble( "A" = c("Constant term", "Y1 lag","Y2 lag"),
          "Simulation Parameter Y1" 
          = c(round(mean(posterior.sample.draws.p[["A.posterior"]][1,1,]),4),
              round(mean(posterior.sample.draws.p[["A.posterior"]][2,1,]),4),
              round(mean(posterior.sample.draws.p[["A.posterior"]][3,1,]),4)),
           "Simulation Parameter Y2" 
          = c(round(mean(posterior.sample.draws.p[["A.posterior"]][1,2,]),4),
              round(mean(posterior.sample.draws.p[["A.posterior"]][2,2,]),4),
              round(mean(posterior.sample.draws.p[["A.posterior"]][3,2,]),4))

  )

kable(basic.model.proof.A, align = "c") %>% 
  kable_styling(font_size = 8, 
                fixed_thead = TRUE, 
                full_width = FALSE, 
                position = "center",
                latex_options = c("HOLD_position"),
                bootstrap_options = c("striped", "hover", "bordered", "responsive", "dark"))

```

Table 2 Basic Model Proofing Simulation for $A$

 - The posterior mean of the $\Sigma$ is:

```{r Basic Model Proof Sigma, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

basic.model.proof.Sigma <-
  tibble( "Sigma" = c("Y1 lag","Y2 lag"),
          "Simulation Parameter Y1" 
          = c(round(mean(posterior.sample.draws.p[["Sigma.posterior"]][1,1,]),4),
              round(mean(posterior.sample.draws.p[["Sigma.posterior"]][2,1,]),4)),
           "Simulation Parameter Y2" 
          = c(round(mean(posterior.sample.draws.p[["Sigma.posterior"]][1,2,]),4),
              round(mean(posterior.sample.draws.p[["Sigma.posterior"]][2,2,]),4))

  )

kable(basic.model.proof.Sigma, align = "c") %>% 
  kable_styling(font_size = 8, 
                fixed_thead = TRUE, 
                full_width = FALSE, 
                position = "center",
                latex_options = c("HOLD_position"),
                bootstrap_options = c("striped", "hover", "bordered", "responsive", "dark"))

```

Table 3 Basic Model Proofing Simulation for $\Sigma$

### Model Extension

The model extension base on a hierarchical model. The gamma distribution on the Minnesota shrinkage parameter lambda $\lambda$ is introduced to adjust $V$.

#### Prior Distribution and Posterier Distribution Specified

**Step 1**: Prior distribution is presented below. We will specify $\underline{A}$, $\underline{V}$, $\underline{S}$, $\underline{\nu}$ by Minnesota shrinkage parameter lambda $\lambda$.

$$
\begin{align}
p(A,\Sigma, \lambda |Y,X) &\propto L(A,\Sigma | Y,X) \ p(A,\Sigma, \lambda) \\
&\propto L(A,\Sigma | Y,X)  \ p(A |\Sigma, \lambda) \ p(\Sigma) \ p(\lambda)
\end{align}
$$

where, each $p(A |\Sigma, k)$, $p(\Sigma)$, $p(k)$ is specified below:

$$
\begin{align}
A |\Sigma, \lambda &\sim \mathcal{MN}_{K\times N}(\underline{A}, \Sigma, \lambda\underline{V}) \\
\Sigma &\sim \mathcal{IW}_{N}(\underline{S},\underline{\nu}) \\
\lambda &\sim \mathcal{Gamma}(\underline{k_{\lambda}}, \underline{\theta_{\lambda}} ) \\ 
\end{align}
$$

The prior distribution is shown in the same way as the Step 1 of basic model.

**Step 2**: Posterior distribution shows below with the implementation of the specification in Step 1 by multiply $L(A,\Sigma | Y,X) \ p(A |\Sigma, \lambda) \ p(\Sigma) \ p(\lambda)$

The probability density function of Gamma distribution is:

$$
f(x;k,\theta) = \frac{x^{k-1}e^{-\frac{x}{\theta}}}{\theta^k \ \Gamma(k)} \quad  \quad   for  \ x>0, and \  k,\theta >0
$$

The kernel of Gamma distribution is:

$$
p(x|k,\theta) \propto x^{k-1}e^{-\frac{x}{\theta}}
$$

Therefore all kernel shows as follow:

$$
\begin{align}
L(A,\Sigma | Y,X) &= det(\Sigma)^{-\frac{T}{2}}\times exp\left\{ -\frac{1}{2} \mathrm{tr}\left[ \Sigma^{-1}(A-\widehat{A})'X'X (A-\widehat{A})\right]\right\} \times exp\left\{ -\frac{1}{2} \mathrm{tr}\left[ \Sigma^{-1}(Y-X\widehat{A})'(Y-X\widehat{A})\right]\right\} \\
p(A |\Sigma, \lambda) &= det(\Sigma)^{-\frac{K}{2}}det(\lambda \underline{V} )^{-\frac{N}{2}}exp\left\{ -\frac{1}{2} \mathrm{tr}\left[ \Sigma^{-1} (A-\underline{A})' (\lambda\underline{V})^{-1} (A-\underline{A})\right]\right\} \\ 
p(\Sigma) &= det(\Sigma)^{\frac{\underline{\nu}+N+1}{2}}exp\left\{ -\frac{1}{2} \mathrm{tr}\left[ \Sigma^{-1} \underline{S}\right]\right\}  \\
p(\lambda) &= \lambda ^{\underline{k_{\lambda}}-1}e^{-\frac{\lambda}{\underline{\theta_{\lambda}}}}
\end{align}
$$

-   The kernel of the fully conditional posterior distribution of $A$ and $\Sigma$:

$$
\begin{align}
p(A,\Sigma |Y,X, \lambda) &\propto L(Y,X|A,\Sigma)p(A |\Sigma, \lambda)p(\Sigma) \\
&\propto \det(\Sigma)^{-\frac{T+N+K+\underline{\nu}+1}{2}} \\
&\times \exp\left\{ -\frac{1}{2} \mathrm{tr}[\Sigma^{-1}[(A-\overline{A})'\overline{V}^{-1}(A-\overline{A})+\underline{S}+Y'Y+\underline{A}'(\lambda\underline{V})^{-1}\underline{A}-\overline{A}'\overline{V}^{-1}\overline{A}]  ] \right\} \\
\end{align}
$$

Now, we can get:

$$
\begin{align}
\overline{A} &= \overline{V}(X'Y+(\lambda\underline{V})^{-1}\underline{A}) \\
\overline{V} &= (X'X + (\lambda\underline{V})^{-1})^{-1}\\
\overline{S} &= \underline{S}+Y'Y+\underline{A}'(\lambda\underline{V})^{-1}\underline{A}-\overline{A}'\overline{V}^{-1}\overline{A} \\
\overline{\nu} &= T+\underline{\nu}
\end{align}
$$

-   The kernel of the fully conditional posterior distribution of $\lambda$:

$$
\begin{align}
p(\lambda |Y,X,A,\Sigma ) &\propto L(Y,X|A,\Sigma)p(A,\Sigma, \lambda)\\
&\propto L(Y,X|A,\Sigma)p(A |\Sigma, \lambda)p(\Sigma)p(\lambda) \\
&\propto p(A |\Sigma, \lambda)p(\lambda) 
\end{align}
$$

$$
\begin{align}
p(\lambda |Y,X,A,\Sigma ) 
&\propto p(A |\Sigma, \lambda)p(\lambda) \\
&\propto 
det(\lambda \underline{V} )^{-\frac{N}{2}}exp\left\{ -\frac{1}{2} \mathrm{tr}\left[ \Sigma^{-1} (A-\underline{A})' (\lambda\underline{V})^{-1} (A-\underline{A})\right]\right\}  \times \lambda ^{\underline{k_{\lambda}}-1}e^{-\frac{\lambda}{\underline{\theta_{\lambda}}}} \\ 
&\propto 
det(\underline{V} )^{-\frac{N}{2}} \lambda^{-\frac{N}{2}} exp\left\{ -\frac{1}{2} \mathrm{tr}\left[ \Sigma^{-1} (A-\underline{A})' (\lambda\underline{V})^{-1} (A-\underline{A})\right]\right\}  \times \lambda ^{\underline{k_{\lambda}}-1}exp \left\{ -\frac{\lambda}{\underline{\theta_{\lambda}}} \right\} \\
&\propto 
 \lambda^{-\frac{N}{2} + \underline{k_{\lambda}}-1 } exp\left\{ -\frac{1}{2} \mathrm{tr}\left[ \Sigma^{-1} (A-\underline{A})' (\lambda\underline{V})^{-1} (A-\underline{A})\right]-\frac{\lambda}{\underline{\theta_{\lambda}}} \right\} \\
&\propto 
 \lambda^{-\frac{N}{2} + \underline{k_{\lambda}}-1 } exp\left\{ -\frac{\mathrm{tr}\left[ \Sigma^{-1} (A-\underline{A})' (\underline{V})^{-1} (A-\underline{A})\right]}{2\lambda} 
-\frac{\lambda}{\underline{\theta_{\lambda}}} \right\}\\
&\propto 
\lambda^{-\frac{N}{2} + \underline{k_{\lambda}}-1 } 
exp\left\{ \frac{- \left[ \frac{1}{\lambda} \mathrm{tr}  \left[ \Sigma^{-1} (A-\underline{A})' (\underline{V})^{-1} (A-\underline{A})\right]  + \frac{\lambda}{ \frac{1}{2} \underline{\theta_{\lambda}}}\right]}{2} 
\right\}\\
\end{align}
$$

As we can figure out the kernel follows generalized inverse Gaussian distribution (GIG):

$$
f(x;a,b,p)=\frac{(a/b)^{p/2}}{2K_p(\sqrt{ab})}x^{(p-1)}e^{-(ax+b/x)/2}, \quad \quad    x>0
$$

The kernel of GIG:

$$
p(x|a,b,p) \propto x^{p-1}exp \left\{\frac{-(ax+\frac{b}{x})}{2} \right\}
$$

Hence, the full-conditional posterior distribution of $\lambda$ follows a Generalised Inverse Gaussian distribution.

$$
\lambda|Y,X,A,\Sigma \sim \mathcal{GIG}(\overline{a},\overline{b},\overline{p})
$$

Therefore we can get:

$$
\begin{align}
\overline{a} &= \frac{2}{\underline{\theta_{\lambda}} }
\\
\overline{b} &= \mathrm{tr}  \left[ \Sigma^{-1} (A-\underline{A})' (\underline{V})^{-1} (A-\underline{A})\right] 
\\ 
\overline{p} &= -\frac{N}{2} + \underline{k_{\lambda}}
\end{align}
$$

**Step 3**: As $\overline{A}$, $\overline{V}$, $\overline{S}$, $\overline{v}$, $\overline{a}$, $\overline{b}$, $\overline{p}$ are specified:

Initialize $\lambda$ at $\lambda^{(0)}$.

At each iteration $s$:

1.  Draw random matrices for $A^{(s)}$ and $\Sigma^{(s)}$ from $p(A,\Sigma|Y,X,\lambda^{(s-1)})$.

2.  Draw a random number for $\lambda^{(s)}$ from $p(\lambda |Y,X,A^{(s)},\Sigma^{(s)})$.

Repeat 1 and 2 $S_{1} + S_{2}$ times.

Discard the first $S_{1}$ draws that allows the algorithm to converge to the stationary posterior distribution.

Output is the sample draws from the joint posterior distribution $\left\{ {A^{(s)}, \Sigma^{(s)}, \lambda^{(s)}} \right\}^{S_{1}+S_{2}}_{s=S_{1}+1}$.



Function below is `posterior.draws.exten`:

```{r Model Exten, fig.align='center',fig.pos='H'}
#| echo: true
#| message: false
#| warning: false

## Posterior sample draw function for extended model(posterior.draws.exten)
posterior.draws.exten = function (total_S, Y, X){
for (s in 1:total_S){
    # NIW posterior parameters
    V.bar.inv              = t(X)%*%X + diag(1/diag(lambda.posterior[s]* V.prior)) 
    V.bar                  = solve(V.bar.inv)
    A.bar                  = V.bar%*%(t(X)%*%Y + diag(1/diag(lambda.posterior[s]* V.prior))%*%A.prior)
    nu.bar                 = nrow(Y) + nu.prior
    S.bar                  = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(lambda.posterior[s]* V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
    S.bar.inv              = solve(S.bar)
  
    # posterior draws for A and Sigma
    Sigma.posterior.IW     = rWishart(1, df=nu.bar, Sigma=S.bar.inv)
    Sigma.posterior.draw   = apply(Sigma.posterior.IW,3,solve)
    Sigma.posterior[,,s]   = Sigma.posterior.draw
    A.posterior[,,s]       = array(rnorm(prod(c(dim(A.bar),1))),c(dim(A.bar),1))
    L                      = t(chol(V.bar))
    A.posterior[,,s]       = A.bar + L%*%A.posterior[,,s]%*%chol(Sigma.posterior[,,s])
    
    
    # Update parameters for lambda posterior
    p                      = lambda.priors$k - (N)/2              # N=10
    diff_A                 = A.posterior[,,s] - A.prior
    product                = t(diff_A) %*% solve(V.prior) %*% diff_A
    b                      = sum(diag(solve(Sigma.posterior[,,s] %*% product)))
    a                      = 2 / lambda.priors$theta
    
    # Draw next period value for lambda from GIG distribution
    if (s!=total_S){
      lambda.posterior[s+1] = GIGrvg::rgig(n=1, lambda = p, chi = b, psi = a)
    }
  }
  
    output                 = list(A.posterior.exten = A.posterior[,,(S1+1):S2], 
                                  Sigma.posterior.exten = Sigma.posterior[,,(S1+1):S2], 
                                  lambda.posterior.exten = lambda.posterior[(S1+1):S2,])

    return(output)
}
```




#### Function Proofing

```{r Extend Model Function Proof, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

# setup 
kappa.1           = 1                                # shrinkage for A1 to Ap
kappa.2           = 100                              # shrinkage for constant 
S1                = 500                              # determine the burn-in draws
S2                = 9500                             # number of draws from the final simulation
total_S           = S1+S2
A.posterior       = array(NA, dim = c((1+N*p),N,S1+S2))
Sigma.posterior   = array(NA, dim = c(N,N,S1+S2))
k.posterior       = matrix(NA, S1+S2, 1)
k.posterior[1]    = 10                               # set k0 
lambda.posterior  = matrix(NA, S1+S2, 1)

# initial value of lambda
lambda.posterior[1] = 10                               # set lambda0 

# Prior Gamma distribution: k, theta
lambda.priors = list(
  k = 1,
  theta = .1
)

# Applying function 
posterior.extend.draws.p = posterior.draws.exten(total_S = total_S, Y=Y, X=X)
```


After fitting a model that includes a constant term and one lag with artificial data, just like the basic model, the extend model also shows that the posterior mean of both the autoregressive and covariance matrices closely identity matrix, and the posterior mean of the constant term is almost a vector of zeros.

 - The posterior mean of the $A$ is:

```{r Extend Model Proof A, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false
extend.model.proof.A <-
  tibble( "A" = c("Constant term", "Y1 lag","Y2 lag"),
          "Simulation Parameter Y1" 
          = c(round(mean(posterior.extend.draws.p[["A.posterior.exten"]][1,1,]),4),
              round(mean(posterior.extend.draws.p[["A.posterior.exten"]][2,1,]),4),
              round(mean(posterior.extend.draws.p[["A.posterior.exten"]][3,1,]),4)),
           "Simulation Parameter Y2" 
          = c(round(mean(posterior.extend.draws.p[["A.posterior.exten"]][1,2,]),4),
              round(mean(posterior.extend.draws.p[["A.posterior.exten"]][2,2,]),4),
              round(mean(posterior.extend.draws.p[["A.posterior.exten"]][3,2,]),4))
  )

kable(extend.model.proof.A, align = "c") %>% 
  kable_styling(font_size = 8, 
                fixed_thead = TRUE, 
                full_width = FALSE, 
                position = "center",
                latex_options = c("HOLD_position"),
                bootstrap_options = c("striped", "hover", "bordered", "responsive", "dark"))

```

Table 4 Extend Model Proofing Simulation for $A$


 - The posterior mean of the $\Sigma$ is:

```{r Extend Model Proof Sigma, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

extend.model.proof.Sigma <-
  tibble( "Sigma" = c("Y1 lag","Y2 lag"),
          "Simulation Parameter Y1" 
          = c(round(mean(posterior.extend.draws.p[["Sigma.posterior.exten"]][1,1,]),4),
              round(mean(posterior.extend.draws.p[["Sigma.posterior.exten"]][2,1,]),4)),
           "Simulation Parameter Y2" 
          = c(round(mean(posterior.extend.draws.p[["Sigma.posterior.exten"]][1,2,]),4),
              round(mean(posterior.extend.draws.p[["Sigma.posterior.exten"]][2,2,]),4))
  )

kable(extend.model.proof.Sigma, align = "c") %>% 
  kable_styling(font_size = 8, 
                fixed_thead = TRUE, 
                full_width = FALSE, 
                position = "center",
                latex_options = c("HOLD_position"),
                bootstrap_options = c("striped", "hover", "bordered", "responsive", "dark"))

```

Table 5 Extend Model Proofing Simulation for $\Sigma$

## Empirical Analysis -  Model Applying and Forecasing

### Basic Model

```{r Stat Setup for Basic Model, fig.align='center',fig.pos='H'}

## Create Y and X
y             = ts(all_data[,1:ncol(all_data)])     # 10col, 135row
Y             = ts(y[5:nrow(y),], frequency=4)      # 10col, 131row
X             = matrix(1,nrow(Y),1)
for (i in 1:frequency(Y)){
  X           = cbind(X,y[5:nrow(y)-i,])            # 10*4+1=41col, 131row
}
 
## Pre-setup 
N             = ncol(Y)                             # N=10
p             = frequency(Y)                        # p=4
A.hat         = solve(t(X)%*%X)%*%t(X)%*%Y
Sigma.hat     = t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)

# Prior distribution (with Minnesota prior)
kappa.1       = 1                                     # shrinkage for A1 to Ap
kappa.2       = 100                                   # shrinkage for constant 
A.prior       = matrix(0,nrow(A.hat),ncol(A.hat))
# A.prior[2,1]  = 1
# A.prior[7,6]  = 1  
A.prior[2:11,] = diag(10)
V.prior       = diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N)))
S.prior       = diag(diag(Sigma.hat))
nu.prior      = N+2                                   
```

```{r Function Applying, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

## Function Applying
posterior.sample.draws = posterior.draws(S=10000, Y=Y, X=X) # sample use S=10000
A.posterior.simu       = posterior.sample.draws$A.posterior
Sigma.posterior.simu   = posterior.sample.draws$Sigma.posterior

```


```{r Basic Model Forecasting, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

## Two-year ahead forecasting h=8
# set up
h                      = 8
S                      = 10000
Y.h                    = array(NA,c(h,N,S))

# sampling predictive density
for (s in 1:S){
  A.posterior.draw     = A.posterior.simu[,,s]
  Sigma.posterior.draw = Sigma.posterior.simu[,,s]
    x.Ti               = Y[(nrow(Y)-p+1):nrow(Y),]
    x.Ti               = x.Ti[p:1,]
  for (i in 1:h){
    x.T                = c(1,as.vector(t(x.Ti)))
    Y.f                = rmvnorm(1, mean = x.T%*%A.posterior.draw, sigma=Sigma.posterior.draw)
      x.Ti             = rbind(Y.f,x.Ti[1:(p-1),])
    Y.h[i,,s]          = Y.f[1:N]
  }
}

```




Figure 6 presents a 3D visualization of the density intervals for the log CPI and inflation expectations. Inflation expectations show some fluctuations, while the log CPI exhibits a stable increase. as indicated by the narrow bounded confidence intervals (light blue for CPI and light green for inflation expectations). The varying heights of the intervals reflect the level of prediction certainty; as we project further into the future, the intervals become wider and more dispersed due to increased uncertainty. 

```{r 3d forecasting graph on basic model, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

par(mfcol = c(1, 2), mar=c(2,2,2,2)-0.1)

# Log CPI forecasting 
limits.lcpi      = range(Y.h[,1,])
point.lcpi.f     = apply(Y.h[,1,],1,mean)

interval.lcpi.f  = apply(Y.h[,1,],1,hdi,credMass=0.90)
theta            = 180
phi              = 15.5

x                = seq(from=limits.lcpi[1], to=limits.lcpi[2], length.out=100)
z                = matrix(NA,h,99)
for (i in 1:h){
  z[i,]          = hist(Y.h[i,1,], breaks=x, plot=FALSE)$density
}
x                = hist(Y.h[i,1,], breaks=x, plot=FALSE)$mids
yy               = 1:h
z                = t(z)

f4               = persp3D(x=x, y=yy, z=z, phi=phi, theta=theta, 
                           xlab="\ncpi[t+h|t]", ylab="h", zlab="\npredictive densities of cpi",
                           shade=NA, border=NA, ticktype="detailed", nticks=3,cex.lab=1,
                           col=NA,plot=FALSE)
perspbox (x=x, y=yy, z=z, bty="f", col.axis="black", phi=phi, theta=theta, 
          xlab="\nlog.cpi[t+h|t]", ylab="h", zlab="\npredictive densities of cpi", 
          ticktype="detailed", nticks=3,cex.lab=1, col = NULL, plot = TRUE)

polygon3D(x=c(interval.lcpi.f[1,],interval.lcpi.f[2,h:1]), 
          y=c(1:h,h:1), 
          z=rep(0,2*h), 
          col = blue2, NAcol = blue5, border = NA, add = TRUE, plot = TRUE)

for (i in 1:h){
  f4.l = trans3d(x=x, y=yy[i], z=z[,i], pmat=f4)
  lines(f4.l, lwd=1, col=blue3)
}
f4.l1 = trans3d(x=point.lcpi.f, y=yy, z=0, pmat=f4)
lines(f4.l1, lwd=1.5, col=green1)



# Expected inflation rate forecasting 
limits.infexp      = range(Y.h[,2,])
point.infexp.f     = apply(Y.h[,2,],1,mean)

interval.infexp.f  = apply(Y.h[,2,],1,hdi,credMass=0.90)

x                = seq(from=limits.infexp[1], to=limits.infexp[2], length.out=100)
z                = matrix(NA,h,99)
for (i in 1:h){
  z[i,]          = hist(Y.h[i,2,], breaks=x, plot=FALSE)$density
}
x                = hist(Y.h[i,2,], breaks=x, plot=FALSE)$mids
yy               = 1:h
z                = t(z)

f4               = persp3D(x=x, y=yy, z=z, phi=phi, theta=theta, 
                           xlab="\ninfexp[t+h|t]", ylab="h", zlab="\npredictive densities of infexp",
                           shade=NA, border=NA, ticktype="detailed", nticks=3,cex.lab=1,
                           col=NA,plot=FALSE)
perspbox (x=x, y=yy, z=z, bty="f", col.axis="black", phi=phi, theta=theta, 
          xlab="\ninfexp[t+h|t]", ylab="h", zlab="\npredictive densities of infexp", 
          ticktype="detailed", nticks=3,cex.lab=1, col = NULL, plot = TRUE)

polygon3D(x=c(interval.infexp.f[1,],interval.infexp.f[2,h:1]), 
          y=c(1:h,h:1), 
          z=rep(0,2*h), 
          col = green5, NAcol = green2, border = NA, add = TRUE, plot = TRUE)

for (i in 1:h){
  f4.l = trans3d(x=x, y=yy[i], z=z[,i], pmat=f4)
  lines(f4.l, lwd=1, col=green6)
}
f4.l1 = trans3d(x=point.infexp.f, y=yy, z=0, pmat=f4)
lines(f4.l1, lwd=1.5, col=green1)

```

Figure 6 3D forecasting graph on basic model

```{r Basic Model forecast data transform, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false
# transform cpi into inflation rate, collect with it with infexp and cash rate

## transform cpi into inflation rate
point.lcpi.h            = ts(apply(Y.h[,1,],1,mean))
dates <- as.Date(c("2024-03-31", "2024-06-30", "2024-09-30", "2024-12-31",
                   "2025-03-31", "2025-06-30", "2025-09-30", "2025-12-31"))
point.lcpi.h<- xts(point.lcpi.h, order.by = dates)

lcpi.data.h             = c(lcpi_data["/2023-12-31"], point.lcpi.h)
cpi.data.h              = exp(lcpi.data.h)
cpi.lag4.h = lag(cpi.data.h, 4)
inf.data.h = ((cpi.data.h / cpi.lag4.h)-1)*100
inf.data.h = na.omit(inf.data.h)


## inflation expectation

point.infexp.h            = ts(round(apply(Y.h[,2,],1,mean),6))
point.infexp.h            = xts(point.infexp.h, order.by = dates)
infexp.data.h             = c(infexp_data["/2023-12-31"], point.infexp.h )

## cash rate

point.crt.h            = ts(round(apply(Y.h[,4,],1,mean),6))
point.crt.h            = xts(point.crt.h, order.by = dates)
crt.data.h             = c(crt_data["/2023-12-31"], point.crt.h )

key_data.h           = na.omit(merge(inf.data.h, infexp.data.h, crt.data.h))
colnames(key_data.h) = c("inf_data.h", "infexp_data.h", "crt_data.h")

```


After an in-depth examination of key variables and converting the log CPI to CPI to calculate the inflation rate for the next eight periods (Figure 7), we found contrary results. Both the inflation rate and inflation expectations show a downward trend. Although they will remain within the RBA's target range for a while, they are expected to fall below 2% after 2025. As for people's inflation expectations, the forecast indicates a fluctuating decline.


```{r Basic Model Key Data Plot, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

num.h      = nrow(key_data.h)
num        = num.h-h
data_df    = fortify.zoo(key_data.h)

par(mfcol = c(1, 1), mar = c(4, 4, 2, 2) +2)

plot(data_df$Index, data_df$inf_data.h, type = "l", col = blue1,
     xlab = "Date", ylab = "Rate (%)", ylim = c(0, 11))

rect(xleft = min(data_df$Index), xright = max(data_df$Index),
     ybottom = 2, ytop = 3, col = green5, border = NA)  

lines(data_df$Index[1:num], data_df$inf_data.h[1:num], col = blue1)
lines(data_df$Index[1:num], data_df$infexp_data.h[1:num], col = green2)

lines(data_df$Index[num:length(data_df$Index)], data_df$inf_data.h[num:length(data_df$Index)], col = blue4)
lines(data_df$Index[num:length(data_df$Index)], data_df$infexp_data.h[num:length(data_df$Index)], col = green3)

abline(v = data_df$Index[136], col = green1, lty = 2) 
abline(h = 0, col = green1, lty = 1) 

legend("topright", legend = c("Inflation Rate", "Expected Inflation Rate", "Inflation Rate Forecast", "Expected Inflation Rate Forecast", "2023-12-31"),
       col = c(blue1, green2, blue4, green3, green1), lty = 1, cex = 0.6)
title(main = "Inflation Rate vs Expected Inflation Rate Forecasing by Basic Model")

```

Figure 7 Basic Model Key Data Plot

### Extension Model

```{r Stat Setup for Extend model, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false
# setup 
S1                = 500                            # determine the burn-in draws
S2                = 9500                           # number of draws from the final simulation

# Prior Gamma distribution: k, theta
lambda.priors = list(
  k = 1,
  theta = .1
)

total_S           = S1+S2
A.posterior       = array(NA, dim = c((1+N*p),N,S1+S2))
Sigma.posterior   = array(NA, dim = c(N,N,S1+S2))
lambda.posterior  = matrix(NA, S1+S2, 1)

# initial value of lambda
lambda.posterior[1] = 10                               # set lambda0 

```

```{r Extension Function Applying, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

## Function Applying
posterior.extend.draws     = posterior.draws.exten(total_S = total_S, Y=Y, X=X)
A.posterior.ext.simu       = posterior.extend.draws[["A.posterior.exten"]]
Sigma.posterior.ext.simu   = posterior.extend.draws[["Sigma.posterior.exten"]]

```

```{r Extension Function Foracasting, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false
## two-year ahead forecasting h=8
# set up
h                 = 8
S                 = 9000
Y.h.ext           = array(NA,c(h,N,S))

# sampling predictive density
for (s in 1:S){
  A.posterior.draw         = A.posterior.ext.simu[,,s]
  Sigma.posterior.draw     = Sigma.posterior.ext.simu[,,s]
    x.Ti                   = Y[(nrow(Y)-p+1):nrow(Y),]
    x.Ti                   = x.Ti[p:1,]
  for (i in 1:h){
    x.T                    = c(1,as.vector(t(x.Ti)))
    Y.f                    = rmvnorm(1, mean = x.T%*%A.posterior.draw, sigma=Sigma.posterior.draw)
      x.Ti                 = rbind(Y.f,x.Ti[1:(p-1),])
    Y.h.ext[i,,s]          = Y.f[1:N]
  }
}
```

Figure 8 presents a 3D visualization of the density intervals for the log CPI and inflation expectations calculated by the extension model. The results are generally similar to those of the basic model, with the only difference being that the log CPI shows a downward trend instead of an upward one.

```{r 3d forecasting graph on extension model, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

par(mfcol = c(1, 2), mar=c(2,2,2,2)-0.1)

# Log CPI forecasting 
limits.lcpi.ext      = range(Y.h.ext[,1,])
point.lcpi.f.ext     = apply(Y.h.ext[,1,],1,mean)

interval.lcpi.f.ext  = apply(Y.h.ext[,1,],1,hdi,credMass=0.90)

x                = seq(from=limits.lcpi.ext[1], to=limits.lcpi.ext[2], length.out=100)
z                = matrix(NA,h,99)
for (i in 1:h){
  z[i,]          = hist(Y.h.ext[i,1,], breaks=x, plot=FALSE)$density
}
x                = hist(Y.h.ext[i,1,], breaks=x, plot=FALSE)$mids
yy               = 1:h
z                = t(z)

f4               = persp3D(x=x, y=yy, z=z, phi=phi, theta=theta, 
                           xlab="\ncpi[t+h|t]", ylab="h", zlab="\npredictive densities of cpi",
                           shade=NA, border=NA, ticktype="detailed", nticks=3,cex.lab=1,
                           col=NA,plot=FALSE)
perspbox (x=x, y=yy, z=z, bty="f", col.axis="black", phi=phi, theta=theta, 
          xlab="\nlog.cpi[t+h|t]", ylab="h", zlab="\npredictive densities of cpi", 
          ticktype="detailed", nticks=3,cex.lab=1, col = NULL, plot = TRUE)

polygon3D(x=c(interval.lcpi.f.ext[1,],interval.lcpi.f.ext[2,h:1]), 
          y=c(1:h,h:1), 
          z=rep(0,2*h), 
          col = blue2, NAcol = blue5, border = NA, add = TRUE, plot = TRUE)

for (i in 1:h){
  f4.l = trans3d(x=x, y=yy[i], z=z[,i], pmat=f4)
  lines(f4.l, lwd=1, col=blue3)
}
f4.l1 = trans3d(x=point.lcpi.f.ext, y=yy, z=0, pmat=f4)
lines(f4.l1, lwd=1.5, col=green1)

# Expected inflation rate forecasting 
limits.infexp.ext      = range(Y.h[,2,])
point.infexp.f.ext     = apply(Y.h[,2,],1,mean)

interval.infexp.f.ext  = apply(Y.h[,2,],1,hdi,credMass=0.90)

x                = seq(from=limits.infexp.ext[1], to=limits.infexp.ext[2], length.out=100)
z                = matrix(NA,h,99)
for (i in 1:h){
  z[i,]          = hist(Y.h[i,2,], breaks=x, plot=FALSE)$density
}
x                = hist(Y.h[i,2,], breaks=x, plot=FALSE)$mids
yy               = 1:h
z                = t(z)

f4               = persp3D(x=x, y=yy, z=z, phi=phi, theta=theta, 
                           xlab="\ninfexp[t+h|t]", ylab="h", zlab="\npredictive densities of infexp",
                           shade=NA, border=NA, ticktype="detailed", nticks=3,cex.lab=1,
                           col=NA,plot=FALSE)
perspbox (x=x, y=yy, z=z, bty="f", col.axis="black", phi=phi, theta=theta, 
          xlab="\ninfexp[t+h|t]", ylab="h", zlab="\npredictive densities of infexp", 
          ticktype="detailed", nticks=3,cex.lab=1, col = NULL, plot = TRUE)

polygon3D(x=c(interval.infexp.f.ext[1,],interval.infexp.f.ext[2,h:1]), 
          y=c(1:h,h:1), 
          z=rep(0,2*h), 
          col = green5, NAcol = green2, border = NA, add = TRUE, plot = TRUE)

for (i in 1:h){
  f4.l = trans3d(x=x, y=yy[i], z=z[,i], pmat=f4)
  lines(f4.l, lwd=1, col=green6)
}
f4.l1 = trans3d(x=point.infexp.f.ext, y=yy, z=0, pmat=f4)
lines(f4.l1, lwd=1.5, col=green1)
```

Figure 8 3d forecasting graph on extension model

```{r Extend Model forecast data transform, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

# transform cpi into inflation rate, collect with it with infexp and cash rate

## transform cpi into inflation rate
point.lcpi.h.ext            = ts(apply(Y.h.ext[,1,],1,mean))
point.lcpi.h.ext            = xts(point.lcpi.h.ext, order.by = dates)


lcpi.data.h.ext             = c(lcpi_data["/2023-12-31"], point.lcpi.h.ext)
cpi.data.h.ext              = exp(lcpi.data.h.ext)
cpi.lag4.h.ext              = lag(cpi.data.h.ext , 4)
inf.data.h.ext              = ((cpi.data.h.ext/cpi.lag4.h.ext)-1)*100
inf.data.h.ext              = na.omit(inf.data.h.ext)


## inflation expectation

point.infexp.h.ext          = ts(round(apply(Y.h.ext[,2,],1,mean),6))
point.infexp.h.ext          = xts(point.infexp.h.ext , order.by = dates)
infexp.data.h.ext           = c(infexp_data["/2023-12-31"], point.infexp.h.ext  )


## cash rate

point.crt.h.ext             = ts(round(apply(Y.h.ext[,4,],1,mean),6))
point.crt.h.ext             = xts(point.crt.h.ext, order.by = dates)
crt.data.h.ext              = c(crt_data["/2023-12-31"], point.crt.h.ext)

key_data.h.ext              = na.omit(merge(inf.data.h.ext, infexp.data.h.ext, crt.data.h.ext))
colnames(key_data.h.ext)    = c("inf_data.h", "infexp_data.h", "crt_data.h")

```


For the analysis of key data, we can see that the extension model presents a more aggressive outlook compared to the basic model (Figure 9). The expected inflation rate continues to decline over the next eight quarters, reaching negative values by the end of 2024 (deflation). People's inflation expectations are also volatile, fluctuating within the 0%-2% range.

```{r Extend Model Key Data Plot, fig.align='center',fig.pos='H'}
#| echo: false
#| message: false
#| warning: false

num.h      = nrow(key_data.h.ext)
num        = num.h-h
data_df    = fortify.zoo(key_data.h.ext)

par(mfcol = c(1, 1), mar = c(4, 4, 2, 2) +2)

plot(data_df$Index, data_df$inf_data.h, type = "l", col = blue1,
     xlab = "Date", ylab = "Rate (%)", ylim = c(-1, 11))

rect(xleft = min(data_df$Index), xright = max(data_df$Index),
     ybottom = 2, ytop = 3, col = green5, border = NA)  

lines(data_df$Index[1:num], data_df$inf_data.h[1:num], col = blue1)
lines(data_df$Index[1:num], data_df$infexp_data.h[1:num], col = green2)

lines(data_df$Index[num:length(data_df$Index)], data_df$inf_data.h[num:length(data_df$Index)], col = blue4)
lines(data_df$Index[num:length(data_df$Index)], data_df$infexp_data.h[num:length(data_df$Index)], col = green3)

abline(v = data_df$Index[136], col = green1, lty = 2) 
abline(h = 0, col = green1, lty = 1) 

legend("topleft", legend = c("Inflation Rate", "Expected Inflation Rate", "Inflation Rate Forecast", "Expected Inflation Rate Forecast", "2023-12-31"),
       col = c(blue1, green2, blue4, green3, green1), lty = 1, cex = 0.6)
title(main = "Inflation Rate vs Expected Inflation Rate Forecasing by Extend Model")

```

Figure 9 Extend Model Key Data Plot

## References {.unnumbered}
